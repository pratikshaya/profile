<!doctype html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>Bhuwan Bhattarai | Resume</title>
        <link rel="stylesheet" href="css/style.css">
        <link href="https://fonts.googleapis.com/css?family=Merriweather:300,400,700|Source+Sans+Pro:400,400i" rel="stylesheet">

	<meta charset="utf-8">
    	<meta name="description" content="Bhuwan Bhattarai information page.">
    	<meta name="keywords" content="Bhuwan Bhattarai, Tangramob">
    	<meta name="author" content="Bhuwan Bhattarai">
    	<!-- Semantic UI + Semantic Icons -->
    	<link rel="stylesheet" type="text/css" href="css/semantic.min.css">
    	<link rel="stylesheet" type="text/css" href="css/icon.min.css">
    	<link href="https://fonts.googleapis.com/css?family=Raleway:200,300,400" rel="stylesheet">
    	<!-- CSS main file -->
    	<link rel="stylesheet" type="text/css" href="css/main.css">
	<link rel="icon" href="imgs/pp.png">

    <body>

	<div id="header" class="bgimage">
      	<div id="headerinfo">
        <img src="imgs/yy.jpg" class="ui small card image imgjaco">
        <div id="headertext">
          <p id="headername"><span style="font-weight:1000">Bhuwan Bhattarai</p>
          <p id="headerrole">AI Engineer at Jeonbuk National University</p>
          <!-- <p id="headermail">bhubon240@gmail.com</p> -->
          <div id="social-icons">
            <!-- Email reference --->
            <a href="mailto:bhubon240@gmail.com"><img src="imgs/mail.png"></a>

            <!-- Scholar reference --->
            <a href="https://scholar.google.com/citations?user=kdIywCQAAAAJ&hl=en"><img src="imgs/google_scholar.png"></a>
            <!-- Github -->
            <a href="https://github.com/pratikshaya/"><img src="imgs/github.png"></a>
	<!-- ORCID -->
            <a href="https://orcid.org/0000-0001-7014-4868"><img src="imgs/orc.png"></a>
		  
          </div>
        </div>
      	</div>
    	</div>



        <div class="page">
		<div class="section row">
                <div class="contact-info col-right">
			<div><!--img src="yy.jpg" class="ui small card image imgjaco"--></div>


			<div>Mailing Address: Jeonbuk National University, Jeonju city, South Korea</div>

			<div>Phone: (+82)01058119302</div>
					<div><a href="mailto:bhubon240@jbnu.ac.kr">bhubon240@jbnu.ac.kr</a></div>
                    <div><a href="mailto:bhubon240@gmail.com">bhubon240@gmail.com</a></div>
                    
                </div>
            </div>
	

	
	<div class="section row">
                <h2 class="col">Bio</h2>
                <div class="section-text col-right">
                    <div>I am an experience machine/deep learning engineer and can apply the algorithms in 2D
(image) as well as 1D (audio) data. I can effectively self-managed during independent project of whole deep neural network pipeline including data preprocessing, model selection and evaluation strategy to find patterns and predict unseen instances.
I can review and implement the research articles related to deep learning published in tough journals for my own custom data. I have a strong background in the most applicable field of deep learning algorithm
called object detection using state-of-the-art algorithm such as Faster-RCNN/Fast-RCNN, Feature pyramid network, RetinaNet and R-FCN. I also have Strong background and can implement deep learning algorithm such as
CNNs and RNNs, in the field of music and audio for classification and regression purpose. I am proficient in handling the spectral and rhythmic features of audio and music such as MFCC, Spectrogram, Mel-Spectrogram and chromagram. I have an ability to extract each instrumental sounds from music using different existing deep neural network algorithm for source separation. </div>
		
           
            </div></div>

            <div class="section row">
                <h2 class="col">Educations</h2>
                <div class="section-text col-right">
		<div><a href="http://www.jbnu.ac.kr/eng/"><h3><span class="emph">Jeonbuk National University (Ph.D cont......)</h3></a></div>
                   

		<div><a href="http://www.jbnu.ac.kr/eng/"><h3><span class="emph">Jeonbuk National university (Masters degree in computer science)</h3></a></div>
                    <div>2016-2018</div>

		
		<div><a href="https://tribhuvan-university.edu.np/"><h3><span class="emph">Tribhuvan University, Patan Multiple campus (bachelors degree in computer science and information technology)</h3></a></div>
                    <div>2011-2015</div>

		<div><a href="http://www.neb.gov.np/"><h3><span class="emph">National Examination Board(NEB), Caspian Valley College, Kumaripati, Lalitpur(Under HSEB)(Class XII)</h3></a></div>
                    <div>2009-2011</div>

		<div><a href="http://www.neb.gov.np/"><h3><span class="emph">National Examination Board(NEB), Kalyan English Secondary Boarding school</h3></a></div>
                    <div>2008</div>
                </div>
            </div>



            <div class="section row">
                <h2 class="col">PROJECTS</h2>
                
        
        
        		<div class="section-text col-right">
                    <div class="row">
                        <div class="col">
                            <h3>Music Source Seperation</h3>
                        </div>
                    </div>
                       

			<div class="col-md-5">
			<div class="pubimg">
          		<img src="imgs/SS.JPG" scale:2>
       		 	</div>
			</div>

                    <ul class="desc">
			<li>Article title:<b><a href="https://ieeexplore.ieee.org/document/9257356">Parallel Stacked Hourglass Network for Music Source Separation.</a></b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li><b>Prepared Korean traditional song (Pansori) dataset with 3 sources.</li>
			<li>Korean traditional music Pansori dataset, MIR-1K dataset, and DSD100 dataset used in experiment. </li>
                        <li>Proposed a novel parallel stacked hourglass network (PSHN) with multiple band spectrograms.</li>
                        <li>Ablation study on proposed and past architecture.</li>
                        <li>State-of-art result.</li>
			<li>Puplished on <b><a href="https://ieeeaccess.ieee.org/"> IEEE Access </a></b>in Nov. 2020</li>
               
                    </div>
                    
        		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Cow Sound Event Localization and Classification</h3>
                        </div>
                    </div>
                       

			<div class="col-md-5">
			<div class="pubimg">
          		<img src="imgs/Cow_SED.JPG" scale:2>
       		 	</div>
			</div>

                    <ul class="desc">
                        <li>Article title:<b><a href="https://ieeexplore.ieee.org/document/9187249/">Visual Object Detector for Cow Sound Event Detection</a></b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li>Cow sound event detection dataset with 4 class categories.</li>
			<li>CNN used for sound event detection using Cow sound dataset and <a href="https://urbansounddataset.weebly.com/urbansound8k.html">UrbanSound8K dataset.</a></li>
                        <li>Visual object detection architecture (F-RCNN, CF-RCNN, FPN, C-FPC) used for audio event detection (in Log Mel-Spectrogram).</li>
			<li>Compare the proposed CNN and Visual object detection architecture using three test dataset.</li>
			<li>Puplished on <b><a href="https://ieeeaccess.ieee.org/"> IEEE Access </a></b>in Sep. 2020</li>
               
                    </div>
                    
                    
                    
         		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Automatic music mood detection using transfer learning and multilayer perceptron</h3>
                        </div>
                    </div>
                  

			<div class="col-md-5">
			<div class="pubimg">
          		<img src="imgs/aspecus.JPG" scale:1>
       		 	</div>
			</div>

                    <ul class="desc">
                        <li>Article title:<b><a href="http://www.ijfis.org/journal/view.html?doi=10.5391/IJFIS.2019.19.2.88">Automatic Music Mood Detection Using Transfer Learning and Multilayer Perceptron</a></b><b><span style="color:#FF5733;">[Scopus Journal]</span></b></li>
                        <li>EmoMusic dataset</li>
                        <li>Use pretrained CNN for feature extraction and multilayer perceptron for music mood detection.</li>
			
                        <li>various music data augmentation.</li>
			<li>Puplished on <b><a href="http://www.ijfis.org/about/sub01.html"> International Journal of Fuzzy Logic and Intelligent Systems </a></b>in June 2018</li>
               
                    </div>
                    
                    
                    
        		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Facemask States Detection</h3>
                        </div>
                    </div>
                        

			<div class="col-md-5">
			<div class="pubimg">
          		<img src="imgs/Face_mask.JPG" scale:2>
       		 	</div>
			</div>

                    <ul class="desc">
			<li>Article title:<b>Deep Learning Based Face Mask Status Detection for COVID-19.</b><b><span style="color:#FF5733;">[ICMLT conference best paper award]</span></b></li>
                        <li>Semi-automatic visual object labeling tool </li>
                        <li>Facemask detection dataset with three cass categories of with mask, without mask and wrong weared mask.</li>
                        <li>Mask detetion using Faster-RCNN, Cascade FRCNN, FPN and Cascade FPN.</li>        
			<li>Comparision, visualization and analysis of system ability and applications.</li>
			<li>under publication.</li>
			
               
                    </div>
                    
          
          
        		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>CNN Based Sound Event Detection in Cowshed</h3>
                        </div>
                    </div>


			<div class="col-md-5">
			<div class="pubimg">
          		<img src="imgs/Jeju_conf.JPG" scale:2>
       		 	</div>
			</div>


                    <ul class="desc">
                        <li>Article title:<b><a href="http://sigongji.ictc.org/wp/SessionPaperList.asp?code=Session%20III-1">Sound Event Detection in Cowshed using Synthetic data and Convolutional Neural Network</a></b><b><span style="color:#FF5733;">[IEEE Conference]</span></b></li>
                        <li>CNN based sound event detection.</li>
			<li>Sound event annotaion tool.</li>
                        <li>Sound localization and classification.</li>
			<li>Puplished on <b><a href="http://ictc.org/"> ICTC2020 </a></b>in Sep. 2020</li>
               
                    </div>  
                    

		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Music Video Affective Computing (Unsupervised)</h3>
                        </div>
                    </div>
                        
			
			<div class="col-md-5">
			<div class="pubimg">
          		<img src="imgs/unsuper_MV.JPG" scale:2>
       		 	</div>
			</div>

                    <ul class="desc">
			<li>Article title:<b>Music video Emotion Classification using Slow-fast Audio-video Network and Unsupervised Feature Representation.</b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li>Unsupervised and supervised music video emotion classification dataset</li>
                        <li>Autoencoder architecture with audio adn video information.</li>
                        <li>Slow-fast audio-video network to capture spatial and temporal information of music and video.</li>
			<li>Train time information sharing and boosting modules.</li>
			<li>Under review in IEEE transactions in multimedia.</li>
               
		</div>


		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Music Video Affective Computing (Supervised)</h3>
                        </div>
                    </div>
                        <div class="col-right light">Sep. 2020 - Jan. 2021</div>
			
			<div class="col-md-5">
			<div class="pubimg">
          		<img src="imgs/Super_MV.JPG" scale:2>
       		 	</div>
			</div>

                    <ul class="desc">
			<li>Article title:<b>Deep Learning-Based Multimodal Methods for Emotion Classification in Music Video Contents.</b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li>Music video emotion classification dataset (Inproved and Extended version)</li>
                        <li>Ablation study on unimodla and multimodal using music, video and facial expression.</li>
                        <li>Network complexity reduction using novel channel and filter separable convolution.</li>
			<li>Train time information sharing and boosting modules.</li>
			<li>End-to-end training, better result on visual and statistical analysis.</li>
			<li>Accepted on Nature scientific reports</li>
               
		</div>






		<div class="section-text col-right">
		<div class="row">
                        <div class="col">
                            <h3>Sound Event Labeling Tool</h3>
                        </div>
                    </div>
                        <div class="col-right light">Dec. 2019 - Sep. 2020</div>
			
			<div class="col-md-5">
			<div class="pubimg">
          		<img src="imgs/Cow_GUI.JPG" scale:2>
       		 	</div>
			</div>

                    <ul class="desc">
			<li>Article title:<b> A Semi-automatic Sound Annotation Tool for Audio/Video data.</b><b><span style="color:#FF5733;">[SCIE Journal]</span></b></li>
                        <li>Semi-automatic sound event annotation tool using audio and video as input.</li>
                        <li>Automatic event detector is used to detect the audio event.</li>
                        <li>Based on the automatic detector result, an human annotation have to refine the annotation boundary.</li>
			<li>Easy to use, better audio visualization, python based and output in easy CSV data file.</li>
                        <li>Diversified annotation tool for any rare sound event.</li>
			<li>Under review.</li>
               
                    </div>
		

		


		

		
		
		
		

	</div>
	<div class="section row">
                <h2 class="col">Current Research</h2>
                <div class="section-text col-right">
                    <div><a>object detection in images and video</a></div>
                    <div><a>Multiple action recognition in cowshed.</a></div>
                    <div><a>Plant disease detection.</a></div>
                    <div><a>pitch detection in music</a></div>
                    <div><a>Music source seperation.</a></div>

                </div>

            </div>

            <div class="section row">
                <h2 class="col">Language Skills</h2>
                <div class="section-text col-right row">
                    <ul class="skills" style="width:35%">
                        <li>English Language</li>
                        <li>Korean Language</li>
                        <li>Hindi</li>
			<li>Nepali</li>
                    
                    </ul>

                    
                </div>
            </div>
            <div class="section row">
                <h2 class="col">Techincal Skills</h2>
                <div class="section-text col-right row">
                    <ul class="skills" style="width:35%">
                        <li>Programming Languages</li>
                        <li>Deep learning Framework</li>
                        <li>Platforms</li>
                        <!--<li>Networking</li> -->
			<li>I.D.E Skills</li>
                    </ul>
                    <ul class="skills" style="width:35%">
                        <li>Python, C, C++, PHP</li>
                        <li>TensorFlow, Keras, PyTorch</li>
                        <li>Linux, Windows, CUDA/Docker</li>
			<li>Eclipse, UML, PyCharm </li>
                        
                    </ul>
                    
                </div>
            </div>
            
	
	<div class="section row">
                <h2 class="col">References</h2>
                <div class="section-text col-right">
		<div><a href="http://ailab.jbnu.ac.kr/intro_prof.php"><h3><span class="emph">Prof. Joonwhoan Lee</h3></a></div>
                    <div>Ph.D. Adviser</div>
			<div>Institude: <a href="https://www.jbnu.ac.kr/kor/">Jeonbuk National University</a></div>
			<div>Ph No.: +82-63-270-2406, +82-010-9855-2406</div>
			<div>Email: <a href="mailto:chlee@chonbuk.ac.kr">chlee@chonbuk.ac.kr</a></div>
		





		





                </div>
            </div>

            </div>
        </div>
    </body>
    
            </html>
